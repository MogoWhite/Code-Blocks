---
title: 2022-08-09
date: 2022-08-09 12:56
---
人間は発話する時，自発的に手を動かす.このジェスチャーは微妙なニュアンス，内容の補完などの情報伝逹に役に立つ.この10年間で，人間のような外観をもつ一般の家庭に擬人化エージェントとロボットが普及し始めたことで，ジェスチャー生成することは元々のVR，アニメーションなどの領域だけではなく，ヒューマンエージェントインタラクションの研究や応用においても重要な役割を果たしている.

しかし、近年ジェスチャー生成の性能が向上するとともに、ディープフェイク映像を心配する論文の数も増えている.2分間のターゲットデータで、話者のパーソナライズジェスチャー生成できる手法~\cite{Ahuja_2022_CVPR}もある. ‘22]生成されたジェスチャーだけでは、完全に他人になりすますことはできないが、ディープフェイクの顔だけではなく、リアルタイムのジェスチャーなど他の技術と組み合わせることで、仮想の人間を作り出し、悪意を持ってディープフェイクの自然さを向上させることができる.

そこで本研究はジェスチャーによる、ディープフェイク映像検出手法を提案する.一つのディープフェイク検出modalとして研究を行う.生成された会話エージェントと本物の人間を判別できる.ディープフェイク検出で全体の生成されたジェスチャー性能も向上できる.




%−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
\section{関連研究}

最初のジェスチャによるディープフェイク映像検出研究であったため、本研究は、ジェスチャー生成、顔のディープフェイク検出、歩容認証三つの分野の先行研究を参考に実施する.

\subsection{ジェスチャー生成}
最初ジェスチャー生成に関する先行研究の多くがルールベースのシステムを検討している~\cite{huang2012robot}、シンプルで直感的な手法であるため、今ビジネスで主流となっている。

近年、ディープラーニング技術の発展により、データドリブンのシステムがより優れた性能を発揮し、主流になる。

Speech2gesture~\cite{ginosar2019learning}は"in-the-wild "の音声から人物固有のジェスチャーを予測するタスクを提案した。音声からジェスチャーを予測するための事前学習モデルを学習する。しかし、音声は、高レベルの言語セマンティクスを直接エンコードできないので、ある種類のジェスチャー（隠喩など）を予測できない。

Trimodal~\cite{yoon2020speech}は音声テキスト、音声、話者のアイデンティティ三つのコンテキストを利用した新しいend-to-endジェスチャー生成モデルである。音声テキストは高レベルの言語セマンティクスのジェスチャーを生成する.音声入力はビートジェスチャーを生成する.話者のアイデンティティはジェスチャーのスタイルを表現する.

Mix-Stage~\cite{Shelhamer2017FCN}は複数の話者に対して単一のモデルを学習する一方で、各話者のジェスチャーに対して固有のスタイル埋め込みをエンドツーエンドで学習するモデルである、Mix-Stageは音声によるジェスチャー生成を行いながら、ジェスチャーのスタイルに応じた生成モデルを同時で学習することが特徴である.

DiffGAN~\cite{Ahuja_2022_CVPR}はジェスチャー生成のためのクロスモーダル生成モデルの低リソース適応についてモデルである．新しい生成モデル2分間のターゲット学習データで、高リソースソース話者の共音声ジェスチャー生成モデルをターゲット話者に対して効率的にパーソナライズするアプローチ.スタイルトランスファーでパーソナライズジェスチャーを生成できる手法である.