本研究では、単一視点画像からパーツ間の関連性や構造を持った3次元モデルを復元する問題に取り組む。先行研究では、直方体を組み合わせて形状を復元しているため、円柱や球体といった円体の表現に弱い。そこで本研究では、直方体だけでなく円体のパーツを組み合わせることで、表現力を高める。

1	はじめに
近年、3DCADを使う製造業だけでなく、自動運転、ロボット、VRなど、幅広い分野で3次元モデルの需要が拡大している。また3Dプリンタなどの普及により、商業利用だけでなく個人利用も増加している。これらのことから、3次元モデルをより手軽に利用するために、自動生成を行うことが求められている。この自動生成技術の中に、単一視点画像からの3次元再構成がある。従来の単一視点画像からの3次元再構成の欠点は、表面が滑らかで物体の詳細情報が失われている3次元モデルを生成してしまうことである。Hanらの先行研究ではCompositional Generalizability [1]という概念を取り入れた、未発見のカテゴリーに対して頑健な3次元再構成の手法を提案している [2]。
本研究では、単一視点画像の3次元再構成においてパーツ間の関連性及び構造を保持することで、よりリアルな3次元モデルの復元を目的とする。Hanらの先行研究では、直方体のプリミティブを組み合わせることで、パーツ構造を含んだ3次元再構成を行なっているが、円形または球形を含んだ3次元モデルの表現に弱い。この課題に対し、本研究では円柱や球体といった円体のプリミティブも追加することで、表現力を向上させる。
2	関連研究
本項目では、提案手法のベースラインであるHanらの研究手法 [2]について概説する。Hanらの手法では、単一視点画像からパーツのインスタンスマスクを抽出し、４つのモジュールを通して3次元モデルを再構成する。

2.1	パーツのインスタンスマスク抽出
Detectron2 [3]のMask R-CNN [4]モデルを用いて、入力画像の各パーツのインタスタンスマスクを抽出する。ShapeNet [5]のCADモデルから画像をレンダリングし、PartNet [6]の3Dモデルに基づいて、パーツのパラメータを生成する。

2.2	パーツ間の関係予測モジュール
 
図 1　パーツの関係予測モジュール

図1はパーツの関係予測をするモジュールのネットワークアーキテクチャを表している。
このモジュールは、画像とそのマスクから2つのパーツの並進対称性と隣接性を検出する2値分類ネットワークとして構成されている。また関係性の検出は，二値分類問題としてモデル化されている。
入力は1枚のRGB画像と2つのパーツマスクとなっており、入力した２つのパーツの関係が存在する確率が出力される。

2.3	各パーツの直方体の方位予測モジュール
 
図 2　各パーツの方位予測モジュール

図2は各パーツの向きを予測するモジュールのネットワークアーキテクチャを表している。
入力としてRGB画像と2値のパーツマスクを与え、ResNetを用いて画像とパーツマスクの結合から大まかな特徴を抽出し、そこからこの潜在的な特徴を多層パーセプトロンに与え回転の予測をする。
Hanらの研究では、PartNetの3Dモデルよりパーツのパラメータの予測を行っているが、PartNetのような既存のパーツレベルのデータセットのほとんどに方向性のあるバウンディングボックスのアノテーションはない。正解ラベルは通常、GTパーツのセグメンテーションが与えられた主成分分析によって計算されるが、このように生成されたラベルは主成分軸の曖昧さやベースパーツの対称性のために不完全なものとなる。同時に、主成分分析はGTセグメンテーションラベルのノイズに敏感である。これらのことから、曖昧で一貫性のないGTでネットワークを監視することは学習の妨げになる。そこでHanらは対称性に起因する回転の曖昧さに対処するための、順序や符号を区別せずに主軸の集合を推定するアプローチを提案している。

2.4	各パーツの直方体のサイズ予測モジュール
 
図 3　パーツのサイズ予測モジュール

図３は各パーツのサイズを予測するモジュールのネットワークアーキテクチャを表している。このモジュールは、並進対称性を考慮してパーツグループを形成し、各グループに含まれるパーツのサイズ（バウンディングボックスのエッジ長）を予測するように設計されている。
並進対称性を考慮したグループ形成を行うために、並進対称性分類器を学習している。この分類器は、画像とパーツマスクの組み合わせを受け取り、入力されたマスクによって強調された2つのパーツが並進対称性を持つかを予測する。
Hanらの手法では、PointNet [7]を参考にして、各軸を「点」とみなし、その属性（エッジ長）を点単位のセグメンテーション方法で推定している。これにより、軸の順序に対して順列等変量となっている。

2.5	パーツの位置関係予測・組み立てモジュール
 
図 4　パーツの中心と接触点間の相対位置(左)とネットワーク構成図(右)

図4は接触点ベースのパーツ相対位置予測モジュールのネットワークアーキテクチャを表している。パーツの接続関係と隣接するパーツ間の相対的な位置を予測することで、隣接するパーツを組み立てる。
Hanらの手法では、絶対位置を推定すると、形状の大きさや光学軸に沿った平行移動に敏感になり、単純なカテゴリー内での予測の設定であっても性能が大きく損なわれることから、相対位置を予測している。
このモジュールでは、RBG画像とペアになっているパーツに関する情報を入力とし、接触点ベースのアプローチを用いてり強い相対位置の事前予測を組み込み、特徴ベクトルを出力する。


3	提案手法
 
図 5　提案手法

本研究で提案するパーツ構造を含む3次元再構成手法の概略図を図5に示す。
本研究はHanらの手法 [2]をベースにしている。Hanらの研究では直方体のプリミティブを組み合わせることで、入力画像から3次元再構成を行っていた。
 
図 6　GT(左)とHanらの手法の実行結果(右)

図6はHanらが実験に使用した3次元モデルのGTと実行結果を示している。この図から、直方体以外の形状を含む3次元モデルの表現が困難となっていることがわかる。したがって、本研究では直方体だけでなく、円体（円柱・球体）パーツを組み合わせることで、円体
の表現を可能にする。
具体的な提案として、図5で示したように、Hanらの手法に直方体または円体のどちらで近似するかを選ぶ分岐を追加する。

4	実験
提案手法を実装するにあたり、ベースラインとなる手法の再現実装と、提案手法による改善見込みの調査を行った。

4.1	先行手法の再現実装
Hanらの手法は2章で概説したように、パーツのインスタンスセグメンテーションとパーツの属性や位置関係を予測する4つのモジュールによって成り立っている。しかし、現時点でコードが公開されていないため、本研究では再現実装を行う。
まず、パーツのインスタンスセグメンテーションに使用されるDetectron2に含まれるMask R-CNNのデモコードを実行し、図7で示すように、実際にインスタンスセグメンテーションを行うことができることを確認した。

 
 
図 7　元画像（上）とMask R-CNN実行後の画像(下)

現在は4つのモジュールのうち、パーツ間の関係を予測するモジュールと、パーツの方位を予測するモジュールの実装に取り掛かっている。

4.2	提案手法による改善見込み調査
3章で提案した手法により、再構成の結果が改善される3次元モデルの割合を考える。
今回Hanらの手法で使用されているデータセットのPartNetを対象とし、円体パーツが無いと表現が困難な3次元モデルを調査した。
まず、Hanらの手法では学習にPartNetのChairカテゴリーを使用していたことから、Chairカテゴリー内を調査した。しかし、円体パーツを含むモデルが少数であることが判明した。そこで、Hanらの研究でテストとして使われていたTableカテゴリーに着目した。

4.2.1	円体パーツを含むモデルの定義
本研究における、円体パーツを含む3次元モデルの基準例を示す。例としてTableカテゴリーから2つのモデルを選択する。
  
図 8　円体パーツを含むモデルの定義例

本研究では、図８の左のモデルを天板が円形になっているため「円体パーツを含むモデル」、右のモデルは天板も脚も直方体であるため「円体パーツを含まないモデル」として判断する。

4.2.2	調査結果
本調査では、Tableカテゴリーから1000個の3次元モデルをランダムサンプリングした。
調査の結果、円体パーツを含む3次元モデルは約160個あり、この事からTableカテゴリーの10～20%が円体パーツを持つモデルであると考えられる。

5	おわりに
本研究では、直方体や円体パーツを組み合わせた、表現力の高いパーツベースの物体3次元再構成を提案した。提案手法では、Hanらの手法に直方体または円体のどちらかで近似する分岐を追加する。
今後の予定を表1に示す。8月から9月にかけて、Hanらの手法で提案されている４つのモジュールを再現実装する。9月から10月にかけて、ShapeNetやPartNetを使って、再現実装した手法を実行する。また同時進行で提案手法をより具体的なものに落とし込む。11月以降に提案手法を実装し、評価なども行っていくことを予定している。
