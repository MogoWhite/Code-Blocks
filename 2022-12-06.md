---
title: 2022-12-06
date: 2022-12-06 10:13
---
このクロスモーダル翻訳タスクの目的は、話し言葉に沿った自由形式のジェスチャーを生成することであり、我々は2つの課題の解決に向けて取り組んでいる。
(1) 言語-ジェスチャー分布のロングテールからジェスチャーを生成し、生成されたジェスチャーを高精度に維持する。
(2) 言語、音響手がかり、ジェスチャーのサブワード・レベルでのアライメントを行い、これらのモダリティ間のフレームレートの差異を考慮する。
我々は、敵対的重要度サンプリング学習（Adversarial Importance Sampled Learning: AISLe）を導入し、敵対的学習と重要度サンプリングを組み合わせて、精度とカバー率のバランスを取る。

データセットから時計回りに、音声とトランスクリプトは生成器Gθ Theta でサブワード alignmentを経て、自由形式のジェスチャーアニメーションを生成するためにデコードされる。
Ga enc と Gw enc は音響エンコーダと言語エンコーダ、Gattnis はマルチモーダル attention block、Gdec は pose decoder である。

次に、AISLeは識別器Dηの出力に基づいてデータセットの重み付きサンプラーを更新し、ループを完了させる。
is a good approximation of the underlying distribution pdata
平均絶対速度を統計量とするジェスチャー生成の分布。分布のサポート（またはカバレッジ）は、各プロットの上部にある色分けされた線で示されている。モデルの分布とグランドトゥルースの分布のオーバーラップが大きいことが望ましい。
音声ジェスチャーの品質を測定する4つの基準に関して、我々のモデルを先行研究および強力なベースラインと比較する人間の知覚研究。


